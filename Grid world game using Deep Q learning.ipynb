{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gridworld game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def randPair(s,e):\n",
    "    return np.random.randint(s,e), np.random.randint(s,e)\n",
    "\n",
    "#find an array in the depth, dimension of the grid\n",
    "def findLoc(state, obj):\n",
    "    for i in range(0,4):\n",
    "        for j in range(0,4):\n",
    "            if (state[i,j] == obj).all():\n",
    "                return i, j\n",
    "            \n",
    "#initialize the stationary grid, all item are placed deterministically\n",
    "def initGrid():\n",
    "    state = np.zeros((4,4,4))\n",
    "    #place player\n",
    "    state[0,1] = np.array([0,0,0,1])\n",
    "    #place wall\n",
    "    state[2,2] = np.array([0,0,1,0])\n",
    "    #place pit\n",
    "    state[1,1] = np.array([0,1,0,0])\n",
    "    #place goal \n",
    "    state[3,3] = np.array([1,0,0,0])\n",
    "    \n",
    "    return state\n",
    "\n",
    "#initialize player at random location but pit, wall and goal should be stationary\n",
    "def initGridPlayer():\n",
    "    state = np.zeros((4,4,4))\n",
    "    #place player\n",
    "    state[randPair(0,4)] = np.array([0,0,0,1])\n",
    "    #place wall\n",
    "    state[2,2] = np.array([0,0,1,0])\n",
    "    #place pit\n",
    "    state[1,1] = np.array([0,1,0,0])\n",
    "    #place goal\n",
    "    state[3,3] = np.array([1,0,0,0])\n",
    "    \n",
    "    a = findLoc(state, np.array([0,0,0,1]))\n",
    "    w = findLoc(state, np.array([0,0,1,0]))\n",
    "    p = findLoc(state, np.array([0,1,0,0]))\n",
    "    g = findLoc(state, np.array([1,0,0,0]))\n",
    "    \n",
    "    if (not a or not w or not p or not g):\n",
    "        return initGridPlayer()\n",
    "    return state\n",
    "\n",
    "#initialize grid so that player, goal, pit, wall are randomly placed\n",
    "def initGridRand():\n",
    "    state = np.zeros((4,4,4))\n",
    "    #place player\n",
    "    state[randPair(0,4)] = np.array([0,0,0,1])\n",
    "    #place wall\n",
    "    state[randPair(0,4)] = np.array([0,0,1,0])\n",
    "    #place pit \n",
    "    state[randPair(0,4)] = np.array([0,1,0,0])\n",
    "    #place wall\n",
    "    state[randPair(0,4)] = np.array([1,0,0,0])\n",
    "    \n",
    "    a = findLoc(state, np.array([0,0,0,1]))\n",
    "    w = findLoc(state, np.array([0,0,1,0]))\n",
    "    p = findLoc(state, np.array([0,1,0,0]))\n",
    "    g = findLoc(state, np.array([1,0,0,0]))\n",
    "    \n",
    "    #if any of the object are superimposed then call the function again to replace\n",
    "    if (not a or not w or not p or not g):\n",
    "        return initGridRand()\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movement function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeMove(state, action):\n",
    "    #need to locate player in grid\n",
    "    player_loc = findLoc(state, np.array([0,0,0,1]))\n",
    "    wall = findLoc(state, np.array([0,0,1,0]))\n",
    "    pit = findLoc(state, np.array([0,1,0,0]))\n",
    "    goal = findLoc(state, np.array([1,0,0,0]))\n",
    "    \n",
    "    state = np.zeros((4,4,4))\n",
    "    \n",
    "    actions = [[-1,0], [1,0], [0,-1], [0,1]]  #left, right, up, down\n",
    "    #e.g: up => (player row-1, player column+0)\n",
    "    new_loc = (player_loc[0] + actions[action][0], player_loc[1] + actions[action][1])\n",
    "    if (new_loc != wall):\n",
    "        if((np.array(new_loc) <= (3,3)).all() and (np.array(new_loc) >= (0,0)).all()):\n",
    "            state[new_loc][3] = 1\n",
    "            \n",
    "    new_player_loc = findLoc(state, np.array([0,0,0,1]))\n",
    "    if (not new_player_loc):\n",
    "        state[player_loc] = np.array([0,0,0,1])\n",
    "        \n",
    "    #replace pit\n",
    "    state[pit][1] = 1\n",
    "    #replace wall\n",
    "    state[wall][2] = 1\n",
    "    #replace goal\n",
    "    state[goal][0] = 1\n",
    "    \n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLoc(state, level):\n",
    "    for i in range(0,4):\n",
    "        for j in range(0,4):\n",
    "            if (state[i,j][level] == 1):\n",
    "                return i,j\n",
    "            \n",
    "def getReward(state):\n",
    "    player_loc = getLoc(state, 3)\n",
    "    pit = getLoc(state, 1)\n",
    "    goal = getLoc(state, 0)\n",
    "    if(player_loc == pit):\n",
    "        return -10\n",
    "    elif(player_loc == goal):\n",
    "        return 10\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "def dispGrid(state):\n",
    "    grid = np.zeros((4,4), dtype=str)\n",
    "    \n",
    "    player_loc = findLoc(state, np.array([0,0,0,1]))\n",
    "    wall = findLoc(state, np.array([0,0,1,0]))\n",
    "    pit = findLoc(state, np.array([0,1,0,0]))\n",
    "    goal = findLoc(state, np.array([1,0,0,0]))\n",
    "    \n",
    "    for i in range(0,4):\n",
    "        for j in range(0,4):\n",
    "            grid[i,j] = ' '\n",
    "            \n",
    "    if player_loc:\n",
    "        grid[player_loc] = 'P' #player\n",
    "    if wall:\n",
    "        grid[wall] = 'W'\n",
    "    if goal:\n",
    "        grid[goal] = '+'\n",
    "    if pit:\n",
    "        grid[pit] = '-'\n",
    "        \n",
    "    return grid\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['+', ' ', 'W', ' '],\n",
       "       [' ', 'P', ' ', ' '],\n",
       "       [' ', '-', ' ', ' '],\n",
       "       [' ', ' ', ' ', ' ']], dtype='<U1')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = initGridRand()\n",
    "dispGrid(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward: 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[' ', ' ', 'W', ' '],\n",
       "       [' ', ' ', ' ', ' '],\n",
       "       [' ', '-', ' ', ' '],\n",
       "       [' ', ' ', ' ', ' ']], dtype='<U1')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = makeMove(state, 0)\n",
    "#state = makeMove(state, 0)\n",
    "#state = makeMove(state, 0)\n",
    "state = makeMove(state, 2)\n",
    "#state = makeMove(state, 3)\n",
    "#state = makeMove(state, 3)\n",
    "print('Reward: %s' %(getReward(state),))\n",
    "dispGrid(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network as our Q function\n",
    "For the fun part let's build neural network that work as Q function.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gaurav/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(164, input_shape=(64,), kernel_initializer=\"lecun_uniform\")`\n",
      "  \n",
      "/home/gaurav/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(150, kernel_initializer=\"lecun_uniform\")`\n",
      "  \n",
      "/home/gaurav/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(4, kernel_initializer=\"lecun_uniform\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(164, init = 'lecun_uniform', input_shape=(64,)))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(150, init='lecun_uniform'))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "model.add(Dense(4, init='lecun_uniform'))\n",
    "model.add(Activation('linear'))\n",
    "\n",
    "rms = RMSprop()\n",
    "model.compile(loss='mse', optimizer=rms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.10289411, -0.03325115,  0.01939793, -0.07264078]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(state.reshape(1,64), batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game #: 999\n",
      "Epoch 1/1\n",
      "\r",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0306\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "import random\n",
    "epochs = 1000\n",
    "gamma = 0.9\n",
    "epsilon = 1\n",
    "for i in range(epoch):\n",
    "    state = initGrid()\n",
    "    status = 1\n",
    "    #while game is still in progress\n",
    "    while(status == 1):\n",
    "        #we are in state S\n",
    "        #let's run our Q function on s and get Q values for all possible actions\n",
    "        qval = model.predict(state.reshape(1,64), batch_size=1)\n",
    "        if (random.random() < epsilon): #choose random action\n",
    "            action = np.random.randint(0,4)\n",
    "        else: #choose best action from q value\n",
    "            action = (np.argmax(qval))\n",
    "            \n",
    "        #take action and observe new state S'\n",
    "        new_state = makeMove(state, action)\n",
    "        #observe reward\n",
    "        reward = getReward(new_state)\n",
    "        #get max_Q(S',a)\n",
    "        newQ = model.predict(new_state.reshape(1,64), batch_size=1)\n",
    "        maxQ = np.max(newQ)\n",
    "        \n",
    "        y = np.zeros((1,4))\n",
    "        y[:] = qval[:]\n",
    "        \n",
    "        if reward == -1: #non terminal state\n",
    "            update = (reward + (gamma*maxQ))\n",
    "        else:#terminal state\n",
    "            update = reward\n",
    "            \n",
    "        y[0][action] = update #target output\n",
    "        print('Game #: %s' %(i,))\n",
    "        model.fit(state.reshape(1,64), y, batch_size=1, nb_epoch=1, verbose=1)\n",
    "        state = new_state\n",
    "        if reward != -1:\n",
    "            status = 0\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        if epsilon > 0.1:\n",
    "            epsilon -= (1/epochs)\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testAlgo(init=0):\n",
    "    i = 0\n",
    "    if init==0:\n",
    "        state = initGrid()\n",
    "    elif init==1:\n",
    "        state = initGridPlayer()\n",
    "    elif init==2:\n",
    "        state = initGridRand()\n",
    "        \n",
    "    print('Initial state:')\n",
    "    print(dispGrid(state))\n",
    "    status = 1\n",
    "    #while game is still in progress \n",
    "    while(status == 1):\n",
    "        qval = model.predict(state.reshape(1,64), batch_size=1)\n",
    "        action = (np.argmax(qval)) #take action with heightest Q value\n",
    "        print('Move #: %s; taking action: %s' %(i, action))\n",
    "        state = makeMove(state, action)\n",
    "        print(dispGrid(state))\n",
    "        reward = getReward(state)\n",
    "        \n",
    "        if reward != -1:\n",
    "            status = 0\n",
    "            print('Reward: %s' %(reward,))\n",
    "        i += 1 #If we are taking more than 10 action\n",
    "        if (i > 10):\n",
    "            print(\"Game lost too many move\")\n",
    "            break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial state:\n",
      "[[' ' 'P' ' ' ' ']\n",
      " [' ' '-' ' ' ' ']\n",
      " [' ' ' ' 'W' ' ']\n",
      " [' ' ' ' ' ' '+']]\n",
      "Move #: 0; taking action: 3\n",
      "[[' ' ' ' 'P' ' ']\n",
      " [' ' '-' ' ' ' ']\n",
      " [' ' ' ' 'W' ' ']\n",
      " [' ' ' ' ' ' '+']]\n",
      "Move #: 1; taking action: 3\n",
      "[[' ' ' ' ' ' 'P']\n",
      " [' ' '-' ' ' ' ']\n",
      " [' ' ' ' 'W' ' ']\n",
      " [' ' ' ' ' ' '+']]\n",
      "Move #: 2; taking action: 1\n",
      "[[' ' ' ' ' ' ' ']\n",
      " [' ' '-' ' ' 'P']\n",
      " [' ' ' ' 'W' ' ']\n",
      " [' ' ' ' ' ' '+']]\n",
      "Move #: 3; taking action: 1\n",
      "[[' ' ' ' ' ' ' ']\n",
      " [' ' '-' ' ' ' ']\n",
      " [' ' ' ' 'W' 'P']\n",
      " [' ' ' ' ' ' '+']]\n",
      "Move #: 4; taking action: 1\n",
      "[[' ' ' ' ' ' ' ']\n",
      " [' ' '-' ' ' ' ']\n",
      " [' ' ' ' 'W' ' ']\n",
      " [' ' ' ' ' ' ' ']]\n",
      "Reward: 10\n"
     ]
    }
   ],
   "source": [
    "testAlgo(init=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
